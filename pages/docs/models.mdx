# Model references

Below are the resources for Daisykit deep learning models. At the current phase of Daisykit, we are focusing on model deployment and overall architecture. Therefore, source code and tutorial for training may be not available for now.

- **1. Person detection (person_detector) and Human pose (Ultralight-Nano-SimplePose):**
    + Pretrained models: [https://github.com/dog-qiuqiu/Ultralight-SimplePose](https://github.com/dog-qiuqiu/Ultralight-SimplePose).
- **2. Facial landmark:**
    + Training code: [https://github.com/polarisZhao/PFLD-pytorch](https://github.com/polarisZhao/PFLD-pytorch).
    + Model conversion: [https://github.com/nilseuropa/pfld_ncnn/](https://github.com/nilseuropa/pfld_ncnn/).
- **3. Face detection (with wearing_mask output): WearMask**
    + Training & model conversion code: [https://github.com/waittim/mask-detector](https://github.com/waittim/mask-detector).
- **4. Background matting:**
    + Pretrained model: [https://github.com/nihui/ncnn-webassembly-portrait-segmentation](https://github.com/nihui/ncnn-webassembly-portrait-segmentation).
- **5. Human pose estimation: Google MoveNet**
    + Original models: [https://tfhub.dev/google/movenet/singlepose/lightning/4](https://tfhub.dev/google/movenet/singlepose/lightning/4), [https://tfhub.dev/google/movenet/singlepose/thunder/4](https://tfhub.dev/google/movenet/singlepose/thunder/4), [https://tfhub.dev/google/movenet/multipose/lightning/1](https://tfhub.dev/google/movenet/multipose/lightning/1).
    + Converted models from: [https://github.com/FeiGeChuanShu/ncnn_Android_MoveNet](https://github.com/FeiGeChuanShu/ncnn_Android_MoveNet).
- **6. Object detection model: YOLOX**
    + Training & model conversion code: [https://github.com/Megvii-BaseDetection/YOLOX](https://github.com/Megvii-BaseDetection/YOLOX).
    + Converted by FeiGeChuanShu: [https://github.com/FeiGeChuanShu/ncnn-android-yolox](https://github.com/FeiGeChuanShu/ncnn-android-yolox).
